{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8461ded4-2e89-4153-b102-6d10b8cc9e02",
   "metadata": {},
   "source": [
    "# Лабораторная работа: Анализ последовательностей белков с использованием многопоточного и многопроцессного подхода\n",
    "\n",
    "## Цель работы\n",
    "\n",
    "Целью данной работы является изучение особенностей многопоточного и многопроцессного кода. Для достижения поставленной цели необходимо решить следующие задачи:\n",
    "\n",
    "- Освоить написание многопоточного кода с синхронизацией;\n",
    "- Освоить написание многопроцессного кода с синхронизацией;\n",
    "- Сравнить производительность многопоточного и многопроцессного кода.\n",
    "\n",
    "## Описание работы\n",
    "\n",
    "В данной лабораторной работе реализуется программа для анализа аминокислотных последовательностей из FASTA-файла. Для этого необходимо выполнить следующие шаги:\n",
    "\n",
    "1. **Считывание последовательностей из FASTA-файла**.\n",
    "2. **Подсчет аминокислот по разным физико-химическим классам**, включая:\n",
    "   - Гидрофобные;\n",
    "   - Гидрофильные нейтральные;\n",
    "   - Гидрофильные положительные;\n",
    "   - Гидрофильные отрицательные.\n",
    "   \n",
    "   В случае, если встречаются символы, отличные от стандартного алфавита аминокислот, их можно либо отфильтровать, либо учитывать отдельно.\n",
    "\n",
    "3. **Реализация многопоточного анализа последовательностей** с использованием потоков Python (`threading`).\n",
    "4. **Реализация многопроцессного анализа последовательностей** с использованием процессов Python (`multiprocessing`).\n",
    "5. **Обеспечение синхронизации потоков и процессов** при подсчете общего количества найденных аминокислот.\n",
    "6. **Проведение тестирования производительности** разных подходов на малых и больших входных данных.\n",
    "7. **Построение графиков и анализ результатов**.\n",
    "\n",
    "## Реализация программы\n",
    "\n",
    "### Реализация анализа последовательностей\n",
    "\n",
    "Для организации кода используется объектно-ориентированный подход. Создается класс `ProteinAnalyser`, который содержит методы для анализа последовательностей в различных режимах:\n",
    "\n",
    "- **Однопоточный анализ**.\n",
    "- **Многопоточный анализ**.\n",
    "- **Многопроцессный анализ**.\n",
    "\n",
    "1. Подгружаем все нужные библиотеки и создаем словарь с аминокислотами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac99ac0-05b9-4c3e-a942-53d3ebb916d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import threading\n",
    "import multiprocessing\n",
    "from Bio import SeqIO\n",
    "from collections import Counter,defaultdict\n",
    "from queue import Queue\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "amino_acid = {\n",
    "\t'A': 'hydrophobic', 'V': 'hydrophobic', 'L': 'hydrophobic', 'I': 'hydrophobic', 'M': 'hydrophobic',\n",
    "\t'F': 'hydrophobic', 'W': 'hydrophobic', 'P': 'hydrophobic',\n",
    "\t'G': 'hydrophilic neutral', 'S': 'hydrophilic neutral', 'T': 'hydrophilic neutral',\n",
    "\t'C': 'hydrophilic neutral', 'Y': 'hydrophilic neutral', 'N': 'hydrophilic neutral',\n",
    "\t'Q': 'hydrophilic neutral',\n",
    "\t'D': 'hydrophilic negative', 'E': 'hydrophilic negative',\n",
    "\t'K': 'hydrophilic positive', 'R': 'hydrophilic positive', 'H': 'hydrophilic positive',\n",
    "\t'B': 'special', 'Z': 'special', 'X': 'unkown',\n",
    "\t'U': 'hydrophilic neutral'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19663540-d396-4a74-9bf4-424ce22ff908",
   "metadata": {},
   "source": [
    "Создаем класс FileDownloader для манипуляций с файлами. Этот класс скачивает файл по URL ссылки с UNIProt, распаковывает GZ архив, режет и переводит в txt fasta-файл и для усиленной проверки копирует полный файл, определенное кол-во раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90801102-4612-4017-b06e-b9a4cc15cac5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FileDownloader:\n",
    "    def __init__(self, url, output_file, block_size=1024):\n",
    "        self.url = url\n",
    "        self.output_file = output_file\n",
    "        self.block_size = block_size\n",
    "        self.total_size = 0\n",
    "    def get_file_size(self):\n",
    "        response = requests.head(self.url)\n",
    "        self.total_size = int(response.headers.get('content-length', 0))\n",
    "        return self.total_size\n",
    "    def download(self):\n",
    "        response = requests.get(self.url, stream=True)\n",
    "        self.total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "        with open(self.output_file, 'wb') as file, tqdm(\n",
    "                total=self.total_size, unit='B', unit_scale=True, desc=self.output_file\n",
    "        ) as progress_bar:\n",
    "            for data in response.iter_content(self.block_size):\n",
    "                file.write(data)\n",
    "                progress_bar.update(len(data))\n",
    "    def unpack(self):\n",
    "        with gzip.open(self.output_file, 'rb') as f_in:\n",
    "            with open('insulin.fasta', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    def cut(self):\n",
    "        with open('seq100.txt','w') as f100,open('seq1000.txt','w') as f1000, open('seq10000.txt','w') as f10000, open('allseq.txt','w') as alls:\n",
    "            count_100,count_1000,count_10000 = 0,0,0\n",
    "            for seq_record in SeqIO.parse(\"insulin.fasta\", \"fasta\"):\n",
    "                if count_100 < 100:\n",
    "                    f100.write(f\">{seq_record.seq}\\n\".strip('>'))\n",
    "                    count_100 += 1\n",
    "                if count_1000 < 1000:\n",
    "                    f1000.write(f\">{seq_record.seq}\\n\".strip('>'))\n",
    "                    count_1000 += 1\n",
    "                if count_10000 < 10000:\n",
    "                    f10000.write(f\">{seq_record.seq}\\n\".strip('>'))\n",
    "                    count_10000 += 1\n",
    "                alls.write(f\">{seq_record.seq}\\n\".strip('>'))\n",
    "    def masscopy(self,input_txt,output_txt, n):\n",
    "        with open(input_txt, 'r') as infile:\n",
    "            txt_content = infile.read()\n",
    "        with open(output_txt, 'w') as outfile:\n",
    "            for _ in range(n):\n",
    "                outfile.write(txt_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af32d620-53de-4ce9-affc-30af2257e6fd",
   "metadata": {},
   "source": [
    "Создаем класс ProteinAnalyser. Прописываем в нем логику на однопоток, мультипоток и многоядерку. Дополнительно создаем функции для сохранения результатов и для измерения времени работы подклассовых функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d312978-b08e-413a-aed3-56f432e23e5b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProteinAnalyser:\n",
    "    def __init__(self, file):\n",
    "        self.file=file\n",
    "        self.statistics = Counter()\n",
    "    def process_sequence(self, sequence):\n",
    "        return Counter(amino_acid[aa] for aa in sequence.strip() if aa in amino_acid)\n",
    "    def analyse_single_thread(self):\n",
    "        self.statistics.clear()\n",
    "        results = defaultdict(Counter)\n",
    "        with open(self.file, 'r') as file:\n",
    "            for i, seq in enumerate(file):\n",
    "                counts = self.process_sequence(seq)\n",
    "                self.statistics+=counts\n",
    "                results[i+1] = counts\n",
    "        self.save_results(results,'single.txt')\n",
    "    def save_results(self, results, filename):\n",
    "        with open(filename, \"w\") as file:\n",
    "            for i, counts in results.items():\n",
    "                file.write(f\"Sequence {i}: {dict(counts)}\\n\")\n",
    "    def analyse_multi_thread(self, num_threads=4):\n",
    "        self.statistics.clear()\n",
    "        queue = Queue()\n",
    "        results = defaultdict(Counter)\n",
    "        def worker():\n",
    "            while True:\n",
    "                item = queue.get()\n",
    "                if item is None:\n",
    "                    break\n",
    "                i, seq = item\n",
    "                counts = self.process_sequence(seq)\n",
    "                self.statistics += counts\n",
    "                results[i + 1] = counts\n",
    "                queue.task_done()\n",
    "        threads = []\n",
    "        for _ in range(num_threads):\n",
    "            thread = threading.Thread(target=worker)\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "        with open(self.file, 'r') as file:\n",
    "            for i, seq in enumerate(file):\n",
    "                queue.put((i, seq))\n",
    "        queue.join()\n",
    "        for _ in threads:\n",
    "            queue.put(None)\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        self.save_results(results,'multitheads.txt')\n",
    "\n",
    "    def analyse_multi_process(self, num_processes=4):\n",
    "        self.statistics.clear()\n",
    "        manager = multiprocessing.Manager()\n",
    "        queue = manager.Queue()\n",
    "        results = manager.dict()\n",
    "        processes = []\n",
    "        for _ in range(num_processes):\n",
    "            process = multiprocessing.Process(target=ProteinAnalyser.worker, args=(queue, results))\n",
    "            process.start()\n",
    "            processes.append(process)\n",
    "        with open(self.file, 'r') as file:\n",
    "            for i, seq in enumerate(file):\n",
    "                queue.put((i, seq))\n",
    "        queue.join()\n",
    "        for _ in processes:\n",
    "            queue.put(None)\n",
    "        for process in processes:\n",
    "            process.join()\n",
    "        self.statistics = sum(results.values(), Counter())\n",
    "        self.save_results(results,'multiprocecces.txt')\n",
    "    @staticmethod\n",
    "    def worker(queue, results):\n",
    "        while True:\n",
    "            item = queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "            i, seq = item\n",
    "            counts = Counter(amino_acid[aa] for aa in seq.strip() if aa in amino_acid)\n",
    "            results[i + 1] = counts\n",
    "            queue.task_done()\n",
    "            \n",
    "    def measure_time(self, func, *args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        result=end_time - start_time\n",
    "        # print(f\"Execution time for {func.__name__}: {result:.4f} seconds\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8eb6f-f2b6-479d-a39a-ce112769b287",
   "metadata": {},
   "source": [
    "Инницируем скачиваение файла, его распаковку, разрезку и массовое копирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ae0c0-5492-47c4-a4f8-2e56737b4de5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://rest.uniprot.org/uniprotkb/stream?compressed=true&format=txt&query=%28Insulin%29'\n",
    "downloader = FileDownloader(url, 'insulin.fasta.gz')\n",
    "# downloader.download()\n",
    "# downloader.unpack()\n",
    "# downloader.cut()\n",
    "downloader.masscopy('allseq.txt', 'massallseq.txt',50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb02be-2c37-4d10-aac2-5513f61452d5",
   "metadata": {},
   "source": [
    "Создаем две функции для измерения времени работы программы от объема данных и метода работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4869f11-430f-4b22-a548-062dc18f0334",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_files():\n",
    "    file_sizes = ['seq100.txt', 'seq1000.txt', 'massallseq.txt']\n",
    "    times_single = []\n",
    "    times_multi_thread = []\n",
    "    times_multi_process = []\n",
    "\n",
    "    for file in file_sizes:\n",
    "        analyser = ProteinAnalyser(file)\n",
    "        times_single.append(analyser.measure_time(analyser.analyse_single_thread))\n",
    "        times_multi_thread.append(analyser.measure_time(analyser.analyse_multi_thread))\n",
    "        times_multi_process.append(analyser.measure_time(analyser.analyse_multi_process))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(file_sizes, times_single, label='Single-thread', marker='o')\n",
    "    plt.plot(file_sizes, times_multi_thread, label='Multi-thread', marker='o')\n",
    "    plt.plot(file_sizes, times_multi_process, label='Multi-process', marker='o')\n",
    "    plt.xlabel('File')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.title('Time vs File Size for Different Modes')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_threads_processes():\n",
    "    file = 'allseq.txt'  # Фиксированный большой файл\n",
    "    num_threads_processes = [1, 2, 4, 8, 16]  # Число потоков/процессов для тестирования\n",
    "    times_multi_thread = []\n",
    "    times_multi_process = []\n",
    "\n",
    "    for num in num_threads_processes:\n",
    "        analyser = ProteinAnalyser(file)\n",
    "        times_multi_thread.append(analyser.measure_time(analyser.analyse_multi_thread, num_threads=num))\n",
    "        times_multi_process.append(analyser.measure_time(analyser.analyse_multi_process, num_processes=num))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(num_threads_processes, times_multi_thread, label='Multi-thread', marker='o')\n",
    "    plt.plot(num_threads_processes, times_multi_process, label='Multi-process', marker='o')\n",
    "    plt.xlabel('Number of Threads/Processes')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.title('Time vs Number of Threads/Processes')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89136a6-3d3f-4833-856b-4db82ce7345f",
   "metadata": {},
   "source": [
    "Инициируем два теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1c3df-b526-4764-bb6d-3b9fcb03f1bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    test_files()\n",
    "    test_threads_processes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ef58c-fb16-453f-970e-8ea36690335c",
   "metadata": {},
   "source": [
    "# В результате работы этих функций получаем 2 типа графиков.\n",
    "## Первый график получен при выполнении программы на компьютере ЦНИЛа (8 ядер/16 потоков)\n",
    "![](1-MT-MP.jpg)\n",
    "\n",
    "## Второй график получен при выполнении программы на домашнем компьютере (6 ядер/12 потоков) \n",
    "![](homepc.png)\n",
    "\n",
    "## Данный график показывает зависимость скорости работы от кол-ва ядер/потоков на пк ЦНИЛа\n",
    "![](Mtvsmp.jpg)\n",
    "\n",
    "## Зависимость скорости от кол-ва ядер/потоков на домашнем пк\n",
    "![](homepc2.png)\n",
    "\n",
    "## Кол-во символов в файлах\n",
    "![](countaa.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ea68c-b7a6-4bf2-9f7f-5c4b95080cff",
   "metadata": {},
   "source": [
    "# Анализ производительности многопоточной и многопроцессной обработки\n",
    "\n",
    "## График 1: Time vs File Size for Different Modes\n",
    "\n",
    "- **Однопоточный (Single-thread) и многопоточный (Multi-thread) режимы** показывают схожую производительность на небольших файлах.\n",
    "- С увеличением размера файла **время выполнения растет** для всех режимов.\n",
    "- **Многопроцессный (Multi-process) режим становится менее эффективным** на больших файлах, особенно на `allseq.txt`, где время выполнения значительно превышает другие режимы.\n",
    "\n",
    "## График 2: Time vs Number of Threads/Processes\n",
    "\n",
    "- В **многопоточной обработке** время стабилизируется после 2 потоков и незначительно колеблется. Это указывает на ограниченность ускорения из-за накладных расходов или GIL (Global Interpreter Lock).\n",
    "- В **многопроцессной обработке** наблюдается значительный выигрыш при переходе от 1 к 2 процессам, но затем улучшение замедляется, а после 8 процессов время начинает снова расти. Это может быть связано с накладными расходами на управление процессами.\n",
    "\n",
    "## Общие выводы\n",
    "- **Многопоточная обработка** эффективнее при умеренной нагрузке и небольших файлах.\n",
    "- **Многопроцессная обработка** дает значительный выигрыш на начальном этапе, но плохо масштабируется на большое количество процессов.\n",
    "- Для **больших файлов многопоточный режим показывает лучшую стабильность**, а многопроцессный может приводить к значительным задержкам.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23452ea-6aec-4b07-a5cd-042bc8f437e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
